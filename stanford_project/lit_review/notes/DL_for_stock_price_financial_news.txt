====================
Title: Deep Learning for stock market prediction from financial news articles
Date: 2017
====================

====================
Abstract
====================
- Intra-day directional movement prediction of S&P 500 index
- Uses financial news titles and a set of technical indicators
- Focuses on CNN and RNN architectures
- CNN can be better than RNN on catching semantics from texts
- RNN is better on catching context and modeling complex temporal characteristics

====================
Introduction
====================
- Predicting stocks has three approaches:
      1. Technical analysis
             + premise that future behavior of a financial time series
               conditioned to its past
      2. Fundamental analysis
             + based on external information as political and economic factors
             + Taken from news articles
      3. Using both

- Three key points in construction of deep learning models
      1. Definition of prediction horizon
      2. Temporal effect of a news document
      3. Representation type of the information

- On first point, daily prediction is most used
- Indicated to use news a day prior for prediction of the next day
- However, it's shown that info from a week or even a month can affect the price
  of the next day
- Uses a set of 7 technical indicators and financial news titles published the
  day before the prediction day
- Two steps to represent textual data:
      1. word2vec model used to generate a word representation
      2. Average all the word vectors of the same title

====================
Model Design
====================
- In this work, a recurrent convolutional neural network model (RCNN) is used
- Prediction is the daily directional-movements in financial time series using
  news articles and technical indicators as input
- Has four stages:
      1. Input layer
      2. Convolutional layer
      3. Recurrent layer
      4. Output layer

--------------------
Input Layer
--------------------
- Two types of input
- Firstly, technical indicator
      + Takes a delayed sequence of seven technical indicators in chronological
        order
      + Defined by $I \in \math{R}^{7, n}$
      + n is the length of the delay window
- Second one is sequence of news titles
      + Embedding layer takes a sequence of encoded sentences as input 
      + Corresponds to a set of titles of news articles from the day $t$
        arranged in chronological order -> from day t
      + Sentence encoding performed in 2 steps:
            1. word2vec model trained on the continuous bag-of-words
               architecture
                   *Embedding is unique vectors of continuous values of length m for
                    each word in training corpus
            2. Average all the word vectors in a title -> unique vector for
               title
                   *Called sentence vector
                   *Each sentence vector (title) in dataset one-hot encoded
                   *After all this, embedding lookup table is made
      + Advantage of word2vec is that resulting embedding vectors capture
        linguistic regularities

--------------------
Convolutional Layer
--------------------
- Four consecutive operations:
      1. Convolution
      2. Sub-sampling or pooling
      3. Activation
      4. Dropout
- Convolution operator designed to perform one-dimensional convolution, or
  temporal convolution
- Can capture local information through the combinations of sentence vectors
- X = [x_1, x_2, ..., x_L] is title embedded vectors
- W = [w_1, w_2, ..., w_R] is the filter unit
- L is the number of news titles in a day
- m is the length of the embedding vector
- R is the length of the filter window

- 1D convolution:
      + q_j = W \cdot x_{j:j + R - 1} + b
- Uses relu on the convolution
- Since there is a high number of parameters, there may be overfitting
      + Due to this fear, dropout is used with p = 0.5

--------------------
Recurrent Layer
--------------------
- Two separate recurrent layers are used
      + One following the convolution -> sequence of L - R + 1 time steps
      + The other following the technical indicator layer
- LSTM is used for the recurrent layers

--------------------
Output Layer
--------------------
- Traditional, fully connected layer with softmax activation function
- In their work, goal is to forecast the direction of daily price movements of
  S&P 500 index
- [1, 0] means stock price will increase
- [0, 1] means stock price will decrease

====================
Experiments
====================

--------------------
Data Description
--------------------
- Data gathered from Reuter's website
- 106,494 news articles spanning from October 20, 2006 to November 21, 2013
- Main topic of these was financial news
- Created and available at reference [10]
- Days without released news are removed
- Filtered to only include data about a company in S&P 500
 
--------------------
Details of Implementation
--------------------
- To train word embedding, word2vec was used
- Word vector lengths is 300
- Initialized with publicly available vectors that were trained on 100 billion
  words from Google News using the continuous bag of words
- Words not present in the set of pre-trained words are initialized randomly
- Input of model is [L X 300] when L is the number of news in a day t

- They used three different filter windows: [3 X 300], [4 X 300], and [5 X 300]
- Use 64 filter units and stride of 1 and padded
- Window of temporal pooling layer is 2
- Thus, output of conv. (h) is dimension [((L - 2) / 2) + 1 X 192]
- Text LSTM has 128 units
- data LSTM has 50 units

- Used stochastic gradient descent using momentum 0.9 and initial step size
  0.1
